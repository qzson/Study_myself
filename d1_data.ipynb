{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분리<br>\n",
    "#### 홀드아웃 방법의 이론과 실현<br>\n",
    "\n",
    "데이터를 분리하는 방법  \n",
    "\n",
    "- 홀드아웃 방법\n",
    "\n",
    "\n",
    "- k-분할 교차검증\n",
    "\n",
    "---\n",
    "\n",
    "홀드아웃 방법 : 주어진 데이터셋을 train 데이터와 test 데이터 2가지로 분할하는 방법.  \n",
    "\n",
    "scikit-learn 라이브러리(파이썬의 오픈소스 머신러닝 라이브러리)로 홀드아웃 방법을 실현.  \n",
    "\n",
    "- `train_test_split()` 함수 사용\n",
    "\n",
    "`x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=XXX, random_state=66)`  \n",
    "\n",
    "random_state 를 지정하지 않으면 테스트 시, 데이터셋이 고정되지 않고 매번 무작위로 선택됨  \n",
    "\n",
    "데이터셋이 매번 바뀌기 때문에 정밀도도 매번 달라져서 정밀도를 비교하거나 실험을 재현하기 힘들어짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (120, 4)\n",
      "y_train : (120,)\n",
      "X_test : (30, 4)\n",
      "y_test : (30,)\n"
     ]
    }
   ],
   "source": [
    "# 코드 실행에 필요한 모듈을 import합니다.\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Iris 데이터 세트 불러오기\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# X_train, X_test, y_train, y_test에 데이터 저장\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "random_state=0)\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터의 세이프 확인\n",
    "print (\"X_train :\", X_train.shape)\n",
    "print (\"y_train :\", y_train.shape)\n",
    "print (\"X_test :\", X_test.shape)\n",
    "print (\"y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-분할 교차검증의 이론<br>\n",
    "\n",
    "k-분할 교차검증 : 비복원 추출 이용, 훈련 데이터셋을 k개로 분할 후, k-1개의 데이터는 학습 데이터로, 나머지 1개는 모델 테스트에 사용  \n",
    "\n",
    "k개의 모델과 성능 평가를 k개 얻는다. 즉, k회 학습과 평가를 반복하고 k개 성능 평가의 평균(`mean()`)으로 성능을 산출  \n",
    "\n",
    "장단점 : 모든 조합을 시험하기 때문에 보다 안정되고 정확한 모델 평가가 가능, but 홀드아웃 방법보다 k배의 연산이 필요하다는 단점\n",
    "> 즉, 장점은 보유한 데이터를 최대한으로 활용한 성능 측정에 있다  \n",
    "\n",
    "일반적으로 사용되는 k의 값 : 5 ~ 10 (데이터셋이 큰 경우 k값을 크게하여 분할 수를 늘려 좋은 결과를 얻을 수 있다)<br>\n",
    "\n",
    "---\n",
    "\n",
    "k-분할 교차검증 안에는 또 다른 특별한 방법도 있다.\n",
    "- 리브-원-아웃 교차검증 (Leave-One-Out cross-validation, LOOCV)\n",
    "> 작은 데이터셋(예로 50~100행 이하)을 취급하는 경우, 이 방법을 권장  \n",
    "\n",
    "---\n",
    "\n",
    "`scores = cross_val_score(모델, X, y, cv=5)`  \n",
    "\n",
    "* `sklearn.cross_validation`은 `버전 0.20`에서 더 이상 지원되지 않습니다.  \n",
    "\n",
    "* 따라서, `sklearn.model_selection`의 `cross_val_score`를 사용합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드의 실행에 필요한 모듈을 로드\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# \"Iris\"라는 데이터 세트를 가져옵니다\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 머신 러닝 알고리즘 SVM을 사용합니다\n",
    "svc = svm.SVC(C=1, kernel=\"rbf\", gamma=0.001)\n",
    "\n",
    "# 교차 검증법을 이용하여 점수를 요구합니다\n",
    "# 내부에서는 X, y가 각각 X_train, X_test, y_train, y_test처럼 분할 처리됩니다\n",
    "scores = cross_val_score(svc, X, y, cv=5)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터의 크기를 확인합니다\n",
    "print (scores)\n",
    "print (\"평균 점수: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 무엇이 좋은 것인지 아직 잘 모르겠다...  \n",
    "우리는 어떻게 데이터 분리를 해야하는 것인가? Kfold vs TTS (train_test_split)  \n",
    "https://stackoverflow.com/questions/49134338/kfolds-cross-validation-vs-train-test-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과적합<br>\n",
    "\n",
    "주어진 데이터에 과하게 적용되어 올바른 기준을 구축하지 못한 것.\n",
    "\n",
    "즉, 컴퓨터가 데이터를 과하게 학습한 상태를 과적합(overfitting) or 과대적합이라고 한다.\n",
    "\n",
    "---  \n",
    "\n",
    "#### 과적합의 회피<br>\n",
    "\n",
    "- 딥러닝의 `드롭아웃`\n",
    "> 학습시 무작위로 일부 뉴런을 없애는 방법\n",
    "- `정규화`(regularization, normalization)\n",
    "> 편향된 데이터의 영향을 없애는 방법  \n",
    "\n",
    "---\n",
    "\n",
    "과적합 : 데이터를 과하게 학습한 상태\n",
    "\n",
    "과소적합 : 데이터를 제대로 학습하지 못한 상태  \n",
    "\n",
    "- 과적합 모델은 분산(variance)가 크다고 이야기\n",
    "\n",
    "- 과소적합 모델은 편향(bias)가 크다고 이야기  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앙상블 학습<br>\n",
    "\n",
    "ensemble learning은 여러 모델을 학습시킴으로써 일반화를 획득하려는 시도  \n",
    "\n",
    "- 배깅(bagging) : 복수 모델을 동시 학습시켜 예측 결과의 평균을 취하는 것으로 예측 결과의 일반화를 시도\n",
    "\n",
    "- 부스팅(boosting) : 모델 예측 결과에 대한 모델을 만들어 일반화 성능을 높이는 기술\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
